###READ AND SPLIT DATASETS 
import numpy as np
import pandas as pd

All = pd.read_csv('../input/berlin/FNIR_DOX_image.csv')

num_train_examples= 9000

np_train = np.array(All[1:num_train_examples + 1])
np_test = np.array(All[num_train_examples + 1:])


test_images1 = np_test[:, 1:]
test_labels = np_test[:, 0]
train_images1 = np_train[:, 1:]
train_labels1= np_train[:, 0]

#reshape
train_images = train_images1.reshape(-1, 42, 36, 1)    
test_images = test_images1.reshape(-1, 42, 36, 1)

#MODEL 
import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, BatchNormalization, Dropout, LeakyReLU
from keras.callbacks import EarlyStopping

model=Sequential()

input_shape=(42,36,1)
x=0.3
y=3
model.add(Conv2D(32, (y, y), activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(x))

model.add(Conv2D(32, (y, y), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(x))


model.add(Conv2D(32, (y, y), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(x))

model.add(Flatten())
model.add(Dense(256, activation='softmax'))
model.add(Dense(128, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
callback = EarlyStopping(monitor='accuracy', patience=3)
model.summary()


#train
epochs = 45
batch_size = 25
history = model.fit(train_images, train_labels1, 
                    batch_size=batch_size, 
                    epochs=epochs, 
                    verbose=1,
                    validation_data=(test_images, test_labels)
                    
#VISULAIZE DATA
import matplotlib.pyplot as plt
import random
import os
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))
ax1.plot(history.history['loss'], color='b', label="Training loss")
ax1.plot(history.history['val_loss'], color='r', label="validation loss")
ax1.set_xticks(np.arange(1, epochs, 1))
ax1.set_yticks(np.arange(0, 2, 0.1))

ax2.plot(history.history['accuracy'], color='b', label="Training accuracy")
ax2.plot(history.history['val_accuracy'], color='r',label="Validation accuracy")
ax2.set_xticks(np.arange(1, epochs, 1))

legend = plt.legend(loc='best', shadow=True)
plt.tight_layout()
plt.show()
